{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkqTyTQUj1hq",
        "outputId": "fefb5a66-4a8e-4567-8f1e-96161f568ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/IDEA-Research/DINO\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WmJRbG0f7Bt",
        "outputId": "332d12e9-0b44-44bd-d76c-141e40ea9e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DINO'...\n",
            "remote: Enumerating objects: 442, done.\u001b[K\n",
            "remote: Counting objects: 100% (191/191), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 442 (delta 136), reused 96 (delta 96), pack-reused 251 (from 1)\u001b[K\n",
            "Receiving objects: 100% (442/442), 13.43 MiB | 16.34 MiB/s, done.\n",
            "Resolving deltas: 100% (191/191), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!file checkpoint0011_4scale.pth\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g719m2xohS8h",
        "outputId": "a716c6a0-5a8f-4676-e34e-7e1f5a95d2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint0011_4scale.pth: Zip archive data, at least v0.0 to extract, compression method=store\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if the file exists and its size\n",
        "checkpoint_path = '/content/checkpoint0011_4scale.pth'\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(f\"File exists: {checkpoint_path}\")\n",
        "    print(f\"File size: {os.path.getsize(checkpoint_path)} bytes\")\n",
        "else:\n",
        "    print(f\"File not found: {checkpoint_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYXQQW8Sher6",
        "outputId": "36cf92a5-5a2d-4be9-8c41-8e8b9af23fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File exists: /content/checkpoint0011_4scale.pth\n",
            "File size: 235929600 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "checkpoint_path = '/content/checkpoint0011_4scale.pth'\n",
        "\n",
        "try:\n",
        "    # Attempt to load as TorchScript model\n",
        "    model = torch.jit.load(checkpoint_path)\n",
        "    print(\"TorchScript model loaded successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQkVld_HitPq",
        "outputId": "902edcb9-01a5-4eca-f525-8ad3b3c3aad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: PytorchStreamReader failed reading zip archive: failed finding central directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hexdump -C /content/checkpoint0011_4scale.pth | head -n 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j62xZ_MHjMIE",
        "outputId": "1b881608-4de5-49a9-da52-3db0d877a9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00000000  50 4b 03 04 00 00 08 08  00 00 00 00 00 00 00 00  |PK..............|\n",
            "00000010  00 00 00 00 00 00 00 00  00 00 10 00 12 00 61 72  |..............ar|\n",
            "00000020  63 68 69 76 65 2f 64 61  74 61 2e 70 6b 6c 46 42  |chive/data.pklFB|\n",
            "00000030  0e 00 5a 5a 5a 5a 5a 5a  5a 5a 5a 5a 5a 5a 5a 5a  |..ZZZZZZZZZZZZZZ|\n",
            "00000040  80 02 7d 71 00 28 58 05  00 00 00 6d 6f 64 65 6c  |..}q.(X....model|\n",
            "00000050  71 01 63 63 6f 6c 6c 65  63 74 69 6f 6e 73 0a 4f  |q.ccollections.O|\n",
            "00000060  72 64 65 72 65 64 44 69  63 74 0a 71 02 29 52 71  |rderedDict.q.)Rq|\n",
            "00000070  03 28 58 17 00 00 00 74  72 61 6e 73 66 6f 72 6d  |.(X....transform|\n",
            "00000080  65 72 2e 6c 65 76 65 6c  5f 65 6d 62 65 64 71 04  |er.level_embedq.|\n",
            "00000090  63 74 6f 72 63 68 2e 5f  75 74 69 6c 73 0a 5f 72  |ctorch._utils._r|\n",
            "000000a0  65 62 75 69 6c 64 5f 74  65 6e 73 6f 72 5f 76 32  |ebuild_tensor_v2|\n",
            "000000b0  0a 71 05 28 28 58 07 00  00 00 73 74 6f 72 61 67  |.q.((X....storag|\n",
            "000000c0  65 71 06 63 74 6f 72 63  68 0a 46 6c 6f 61 74 53  |eq.ctorch.FloatS|\n",
            "000000d0  74 6f 72 61 67 65 0a 71  07 58 01 00 00 00 30 71  |torage.q.X....0q|\n",
            "000000e0  08 58 06 00 00 00 63 75  64 61 3a 30 71 09 4d 00  |.X....cuda:0q.M.|\n",
            "000000f0  04 74 71 0a 51 4b 00 4b  04 4d 00 01 86 71 0b 4d  |.tq.QK.K.M...q.M|\n",
            "00000100  00 01 4b 01 86 71 0c 89  68 02 29 52 71 0d 74 71  |..K..q..h.)Rq.tq|\n",
            "00000110  0e 52 71 0f 58 3e 00 00  00 74 72 61 6e 73 66 6f  |.Rq.X>...transfo|\n",
            "00000120  72 6d 65 72 2e 65 6e 63  6f 64 65 72 2e 6c 61 79  |rmer.encoder.lay|\n",
            "00000130  65 72 73 2e 30 2e 73 65  6c 66 5f 61 74 74 6e 2e  |ers.0.self_attn.|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/checkpoint0011_4scale.pth -d /content/extracted_files/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwOEpy3Tj_Fw",
        "outputId": "41d9939d-59ee-4362-ece9-ac3358eb6705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/checkpoint0011_4scale.pth\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/checkpoint0011_4scale.pth or\n",
            "        /content/checkpoint0011_4scale.pth.zip, and cannot find /content/checkpoint0011_4scale.pth.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the path to the .pth file\n",
        "checkpoint_path = '/content/checkpoint0011_4scale.pth'\n",
        "\n",
        "# Attempt to load the model checkpoint\n",
        "try:\n",
        "    # Load the model checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
        "\n",
        "    # Print the keys to understand the structure of the checkpoint\n",
        "    print(\"Checkpoint keys:\", checkpoint.keys())\n",
        "\n",
        "    # If the checkpoint contains a 'state_dict', load it into your model\n",
        "    # Assuming you have a ResNet model defined\n",
        "    from torchvision.models import resnet50\n",
        "\n",
        "    model = resnet50()  # Create your model instance\n",
        "\n",
        "    if 'state_dict' in checkpoint:\n",
        "        model.load_state_dict(checkpoint['state_dict'])  # Load weights\n",
        "    else:\n",
        "        model.load_state_dict(checkpoint)  # Directly load if not nested in state_dict\n",
        "\n",
        "    # Move the model to GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    print(\"Model loaded successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"An error occurred while loading the checkpoint:\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJdfpFTAjetR",
        "outputId": "45e0d6cc-24c2-48c2-bc50-273937ebdad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred while loading the checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-a96f47128fa3>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "# Load ResNet-50 model\n",
        "model = resnet50()\n",
        "\n",
        "# Load the pre-trained weights from the checkpoint file\n",
        "checkpoint_path = '/content/checkpoint0011_4scale.pth'\n",
        "\n",
        "# Load the checkpoint\n",
        "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
        "\n",
        "# Optional: Print checkpoint keys to inspect the structure\n",
        "print(checkpoint.keys())\n",
        "\n",
        "# If the checkpoint contains a 'state_dict', load it into the model\n",
        "if 'state_dict' in checkpoint:\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "else:\n",
        "    model.load_state_dict(checkpoint)\n",
        "\n",
        "# Move the model to GPU (if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "-yKXFjCngEy2",
        "outputId": "b763e810-1541-4cd9-f9dd-786cd9d42a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-2d215a3e7c00>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-2d215a3e7c00>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load the checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Optional: Print checkpoint keys to inspect the structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0moverall_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                     warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Switch model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Dummy input for inference (e.g., image data)\n",
        "input_data = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "# Perform inference\n",
        "output = model(input_data)\n"
      ],
      "metadata": {
        "id": "asJgEGZ3gafY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "OLXDDQ-qgdbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/model.pth')\n"
      ],
      "metadata": {
        "id": "a0OiUMM_gkdw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}